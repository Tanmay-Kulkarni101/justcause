{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking causalml learners\n",
    "The aim of this notebook is to compare the performance of the causal learners implemented in the [causalml](https://github.com/uber/causalml) Python package with that of the original R implementations.\n",
    "\n",
    "First, we setup a port to the R implementations using `rpy2`. We then write a simple wrapper function for rboost and rlasso, which can be passed to the evaluation API of *JustCause*. We aim to compare the meta learner with the same base-learners in both cases, which is why we use xgboost and glmnet to provide the same base learners used in the original R implementation.\n",
    "\n",
    "## Details of R implementations\n",
    "### Underlying Base Learners\n",
    "The details of the R implementations used below can be found in the respective files [here](https://github.com/xnie/rlearner/tree/master/R).\n",
    "From our analysis, RLasso uses an ElasticNet with the lasso objective thus we should set `l1_ratio=1`. (See [sklearn docu](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet)). But in the case below we use the `glmnet` package based on the same Fortran library as the original R code used by the rlearner implementation. \n",
    "\n",
    "\n",
    "The details of the RBoost are best replicated by using the xgboost python package, as the authors use the same package in the R implementation. \n",
    "\n",
    "### Propensity Scores \n",
    "The propensity scores in our R-Learner wrapper are calculated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MaximilianFranz/anaconda3/envs/justcause/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/MaximilianFranz/anaconda3/envs/justcause/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "/Users/MaximilianFranz/anaconda3/envs/justcause/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/MaximilianFranz/anaconda3/envs/justcause/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/MaximilianFranz/anaconda3/envs/justcause/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/MaximilianFranz/anaconda3/envs/justcause/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/MaximilianFranz/anaconda3/envs/justcause/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/MaximilianFranz/anaconda3/envs/justcause/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from justcause.learners.utils import install_r_packages\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "from rpy2.robjects.vectors import FloatVector, IntVector, StrVector\n",
    "\n",
    "# activate numpy conversion\n",
    "numpy2ri.activate()\n",
    "\n",
    "install_r_packages(['devtools'])\n",
    "\n",
    "def install_rlearner():\n",
    "    \n",
    "    d = {'package.dependencies': 'package_dot_dependencies',\n",
    "             'package_dependencies': 'package_uscore_dependencies'}\n",
    "    \n",
    "    if not rpackages.isinstalled('rlearner'):\n",
    "        custom_install = importr('devtools',robject_translations = d)\n",
    "        custom_install.install_github(\"xnie/rlearner\")\n",
    "    \n",
    "    return importr('rlearner', robject_translations = d)\n",
    "\n",
    "\n",
    "\n",
    "def rlearner_lasso(train, test):\n",
    "    rlearner = install_rlearner()\n",
    "    train_X, train_t, train_y = train.np.X, train.np.t, train.np.y\n",
    "    test_X, test_t, test_y = test.np.X, test.np.t, test.np.y\n",
    "    \n",
    "    \n",
    "    model = rlearner.rlasso(train_X, IntVector(train_t), FloatVector(train_y))\n",
    "    \n",
    "    return (\n",
    "        np.array(ro.r.predict(model, train_X)).reshape(1, -1)[0], \n",
    "        np.array(ro.r.predict(model, test_X)).reshape(1, -1)[0]\n",
    "           )\n",
    "\n",
    "def rlearner_boost(train, test):\n",
    "    rlearner = install_rlearner()\n",
    "    train_X, train_t, train_y = train.np.X, train.np.t, train.np.y\n",
    "    test_X, test_t, test_y = test.np.X, test.np.t, test.np.y\n",
    "    \n",
    "    \n",
    "    model = rlearner.rboost(train_X, IntVector(train_t), FloatVector(train_y))\n",
    "    \n",
    "    return (\n",
    "        np.array(ro.r.predict(model, train_X)).reshape(1, -1)[0], \n",
    "        np.array(ro.r.predict(model, test_X)).reshape(1, -1)[0]\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from justcause.data.sets import load_ihdp\n",
    "from justcause.evaluation import evaluate_ite\n",
    "from justcause.learners import RLearner\n",
    "from justcause.metrics import pehe_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Working Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = load_ihdp(select_rep=[0])[0] # select first replication only \n",
    "train, test = train_test_split(rep, train_size=0.8)\n",
    "train_ite, test_ite = rlearner_boost(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = load_ihdp(select_rep=[0])[0] # select first replication only \n",
    "train, test = train_test_split(rep, train_size=0.8)\n",
    "train_ite, test_ite = rlearner_lasso(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## R-Learner Lasso : Python vs R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2973aacff1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrlearner_lasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreplications\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ihdp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_ite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplications\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpehe_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/ba/eval/justcause/src/justcause/evaluation.py\u001b[0m in \u001b[0;36mevaluate_ite\u001b[0;34m(replications, methods, metrics, formats, train_size, random_state)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         train_result, test_result = _evaluate_single_method(\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mreplications\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         )\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ba/eval/justcause/src/justcause/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_single_method\u001b[0;34m(replications, method, metrics, formats, train_size, random_state)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mtrain_ite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mtrain_ite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         test_scores = test_scores.append(\n",
      "\u001b[0;32m~/Documents/ba/eval/justcause/src/justcause/evaluation.py\u001b[0m in \u001b[0;36mdefault_predictions\u001b[0;34m(method, train, test)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mtrain_ite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_ite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ba/eval/justcause/src/justcause/learners/meta/rlearner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, t, y, p)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     def predict_ite(\n",
      "\u001b[0;32m~/anaconda3/envs/justcause/lib/python3.7/site-packages/causalml/inference/meta/rlearner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, p, treatment, y, verbose)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training the treatment effect model for {} with R-loss'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             self.models_tau[group].fit(X_filt, (y_filt - yhat_filt) / (w - p_filt),\n\u001b[0;32m--> 110\u001b[0;31m                                        sample_weight=(w - p_filt) ** 2)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvars_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_filt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myhat_filt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'sample_weight'"
     ]
    }
   ],
   "source": [
    "from glmnet import ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "methods = [rlearner_lasso, RLearner(ElasticNet(l1_ratio=1))]\n",
    "replications = load_ihdp(select_rep=np.arange(100))\n",
    "result = evaluate_ite(replications, methods, metrics=pehe_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train</th>\n",
       "      <th>pehe_score-mean</th>\n",
       "      <th>pehe_score-median</th>\n",
       "      <th>pehe_score-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rlearner_lasso</td>\n",
       "      <td>True</td>\n",
       "      <td>6.445494</td>\n",
       "      <td>3.373901</td>\n",
       "      <td>8.140446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rlearner_lasso</td>\n",
       "      <td>False</td>\n",
       "      <td>6.445494</td>\n",
       "      <td>3.373901</td>\n",
       "      <td>8.140446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RLearner(outcome=ElasticNet, effect=ElasticNet)</td>\n",
       "      <td>True</td>\n",
       "      <td>4.128427</td>\n",
       "      <td>2.230457</td>\n",
       "      <td>5.136343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RLearner(outcome=ElasticNet, effect=ElasticNet)</td>\n",
       "      <td>False</td>\n",
       "      <td>4.128427</td>\n",
       "      <td>2.230457</td>\n",
       "      <td>5.136343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            method  train  pehe_score-mean  \\\n",
       "0                                   rlearner_lasso   True         6.445494   \n",
       "1                                   rlearner_lasso  False         6.445494   \n",
       "2  RLearner(outcome=ElasticNet, effect=ElasticNet)   True         4.128427   \n",
       "3  RLearner(outcome=ElasticNet, effect=ElasticNet)  False         4.128427   \n",
       "\n",
       "   pehe_score-median  pehe_score-std  \n",
       "0           3.373901        8.140446  \n",
       "1           3.373901        8.140446  \n",
       "2           2.230457        5.136343  \n",
       "3           2.230457        5.136343  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-Learner Boost : Python vs R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:44:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[10:44:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "methods = [rlearner_boost, RLearner(XGBRegressor())]\n",
    "\n",
    "result = evaluate_ite(, 100, methods, metrics=pehe_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train</th>\n",
       "      <th>pehe_score-mean</th>\n",
       "      <th>pehe_score-median</th>\n",
       "      <th>pehe_score-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rlearner_boost</td>\n",
       "      <td>True</td>\n",
       "      <td>2.036739</td>\n",
       "      <td>0.939122</td>\n",
       "      <td>2.913037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rlearner_boost</td>\n",
       "      <td>False</td>\n",
       "      <td>2.036739</td>\n",
       "      <td>0.939122</td>\n",
       "      <td>2.913037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RLearner(outcome=XGBRegressor, effect=XGBRegre...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.822892</td>\n",
       "      <td>1.373032</td>\n",
       "      <td>4.210576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RLearner(outcome=XGBRegressor, effect=XGBRegre...</td>\n",
       "      <td>False</td>\n",
       "      <td>2.822892</td>\n",
       "      <td>1.373032</td>\n",
       "      <td>4.210576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              method  train  pehe_score-mean  \\\n",
       "0                                     rlearner_boost   True         2.036739   \n",
       "1                                     rlearner_boost  False         2.036739   \n",
       "2  RLearner(outcome=XGBRegressor, effect=XGBRegre...   True         2.822892   \n",
       "3  RLearner(outcome=XGBRegressor, effect=XGBRegre...  False         2.822892   \n",
       "\n",
       "   pehe_score-median  pehe_score-std  \n",
       "0           0.939122        2.913037  \n",
       "1           0.939122        2.913037  \n",
       "2           1.373032        4.210576  \n",
       "3           1.373032        4.210576  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
