=====
Usage
=====

This sections gives you a detailed explanation on how to use JustCause.

The Reason for DGPs
===================
Due to the so called `Fundamental Problem of Causal Inference`_, there is no ground truth for any real treatment effect dataset.
In order to be able to evaluate methods, we thus need to resort to semi- or fully-synthetic data. The process of generating such a
dataset is called a data generating process (DGP). We distinguish between i) an Empirical Monte Carlo Study `[1]`_ which uses
real covariates - the features of real instances (e.g. patients, ...) - and generates a synthetic potential outcome on top of it and
ii) a fully synthetic approach, where covariates are sampled from some distribution.

Briefly, a reference data set following our convention contains these columns with special meaning:

 - ``t``: binary treatment indicator
 - ``y``: observed outcome
 - ``y_cf``: counterfactual outcome
 - ``y_0``: untreated potential outcome with possible noise
 - ``y_1``: treated potential outcome with possible noise
 - ``mu_0``: true untreated potential outcome without noise
 - ``mu_1``: true treated potential outcome without noise
 - ``ite``: true individual treatment effect

For those columns the following relationships hold:

 - ``y = t*y_1 + (1-t)*y_0``
 - ``y_cf = (1-t)*y_1 + t*y_0`` (*counterfactual* of ``y``)
 - ``y = y_0 if t == 0 else y_1``
 - ``y_0 = mu_0 + ε`` and ``y_1 = mu_1 + ε`` where ε is some random noise or 0
 - ``ite = mu_1 - mu_0``

Besides these columns, there are covariates (also called features) and optionally other columns for managing meta information
like datetime or an id of sample. Within the provided data sets covariates are called ``x_1``, ``x_2``, etc. but can take
any name if you use your own data set as explained below. Besides covariates, the provided data set have a column ``sample_id``
to easily identify one sample.

Replications
------------
Since most DGPs are based on some form of random sampling, usually researchers use multiple so called replications of the same data
to avoid a large influence of the randomness underlying the distributions. A replication is generated by
sampling from the probability distributions that define the data.
In the case of IHDP 1000 replications of the same data are used for
a full evaluation, thus ensuring robust evaluation results.

The concept of replications is build into JustCause by design to encourage robust comparisons.


Handling Data
=============

JustCause uses a generalization of a Pandas :class:`~pandas.DataFrame` for managing your data named :class:`~.CausalFrame`.
A CausalFrame encompasses all the functionality of a Pandas DataFrame but additionally keeps track which columns besides
the ones with special meaning like explained above, covariates and others. This allows to easily access them in a programmatic way.

All data sets provided by JustCause are provided as lists of CausalFrames, i.e. for each replication one CausalFrame.
Thus, we get a single CausalFrame ``cf`` from one of the provided data sets by::

    >>> from justcause.data.sets import load_ihdp

    >>> cf = load_ihdp(select_rep=0)[0]  # select replication 0
    >>> type(cf)
    justcause.data.frames.CausalFrame

As usual, ``cf.columns`` would list the names of all columns. To find out which of these columns are *covariates* or
*others*, we can use the attribute accessor ``names``::

    >>> cf.names.covariates
    ['0',
     '1',
     '2',
     '3',
     ...
     '21',
     '22',
     '23',
     '24']
    >>> cf.names.others
    ['sample_id']

This allows us to easily apply transformations for instance only to covariates. In general, this leads to more robust code
since the API of a CausalFrame enforces the differentiation between covariates, columns with special meaning, e.g.
outcome ``y``, treatment ``t`` and other columns such as metadata like a datetime or an id of an observation, e.g. ``sample_id``.

If we want to construct a CausalFrame, we do that just in the same way as with a DataFrame but have to specify covariate columns::

    >>> import justcause as jc
    >>> from numpy.random import rand, randint
    >>> import pandas as pd

    >>> N = 10
    >>> dates = pd.date_range('2020-01-01', periods=N)
    >>> cf = jc.CausalFrame({'c1': rand(N),
    >>>                      'c2': rand(N),
    >>>                      'date': dates,
    >>>                      't': randint(2, size=N),
    >>>                      'y': rand(N)
    >>>                      },
    >>>                      covariates=['c1', 'c2'])

All columns that are neither covariates nor columns with special meaning like ``t`` and ``y`` are treated as *others*::

    >>> cf.names.others
    ['date']

Working with Learners
=====================

Within the PyData stack, `Numpy`_ surely is the lowest common denominator and is thus used by a lot of libraries. Since
JustCause mainly wraps third-party libraries for causal methods under a common API, the decision was taken to only allow
passing Numpy arrays to the learners, i.e. causal methods, within JustCause. This allows for more flexibility and keeps
the abstraction layer to the original method much smaller.

The ``fit`` method of a learner takes at least the parameters ``X`` for the covariate matrix,  ``t`` for the treatment
and ``y`` for the outcome, i.e. target, vector as Numpy arrays. In order to bridge the gap between rich CausalFrames and
plain arrays, a :class:`~.CausalFrame` provides the attribute accessor ``np`` (for *numpy*). Using it, we can easily pass
the covariates ``X``, treatment ``t`` and outcome ``y`` to a learner::

    >>> from sklearn.ensemble import RandomForestRegressor

    >>> reg = RandomForestRegressor()
    >>> learner = jc.learners.SLearner(reg)
    >>> learner.fit(cf.np.X, cf.np.t, cf.np.y)



.. _Numpy: https://numpy.org/
.. _Fundamental Problem of Causal Inference: https://thuijskens.github.io/2016/08/25/causal-modelling/
.. _[1]: https://arxiv.org/pdf/1810.13237.pdf
